{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c9bf25",
   "metadata": {},
   "source": [
    "HAAR CASCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef554ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974adffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     22\u001b[39m         cv2.putText(frame, \u001b[33m\"\u001b[39m\u001b[33mFace Detected\u001b[39m\u001b[33m\"\u001b[39m, (x, y - \u001b[32m10\u001b[39m), cv2.FONT_HERSHEY_SIMPLEX, \u001b[32m0.9\u001b[39m, (\u001b[32m0\u001b[39m,\u001b[32m255\u001b[39m,\u001b[32m0\u001b[39m), \u001b[32m2\u001b[39m, cv2.LINE_AA)\n\u001b[32m     24\u001b[39m     cv2.imshow(\u001b[33m'\u001b[39m\u001b[33mCamera\u001b[39m\u001b[33m'\u001b[39m, frame)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m & \u001b[32m0xFF\u001b[39m == \u001b[38;5;28mord\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     29\u001b[39m cam.release()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Face Detection\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, \"Face Detected\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67844353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to grab frame\n"
     ]
    }
   ],
   "source": [
    "# face + eye + mouth\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (240, 0, 0), 2)\n",
    "        cv2.putText(frame, \"Face Detected\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        mouths = mouth_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)\n",
    "\n",
    "        for (ex,ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(frame, (x+ex,y+ey), (x+ex+ew, y+ey+eh), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, \"Eye\", (x+ex,(y+ey) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        for (mx,my, mw, mh) in mouths:\n",
    "            cv2.rectangle(frame, (x+mx,y+my), (x+mx+mw, y+my+mh), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, \"Mouth\", (x+mx,(y+my) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102c6966",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     17\u001b[39m gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m faces = \u001b[43mface_cascade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[32m     21\u001b[39m     cv2.rectangle(frame, (x, y), (x + w, y + h), (\u001b[32m240\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m), \u001b[32m2\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Load Haar cascade classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (240, 0, 0), 2)\n",
    "        cv2.putText(frame, \"Face\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Detect eyes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "            cv2.putText(roi_color, \"Eye\", (ex, ey - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Detect mouth (smile)\n",
    "        mouths = mouth_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)\n",
    "        smiling = False\n",
    "        for (mx, my, mw, mh) in mouths:\n",
    "            # Only consider mouths below the nose (lower half of the face)\n",
    "            if my > h / 2:\n",
    "                cv2.rectangle(roi_color, (mx, my), (mx + mw, my + mh), (0, 0, 255), 2)\n",
    "                cv2.putText(roi_color, \"Mouth\", (mx, my - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                smiling = True\n",
    "                break  # Only consider one mouth\n",
    "\n",
    "        # Show \"Smiling\" message if a smile is detected\n",
    "        if smiling:\n",
    "            cv2.putText(frame, \"Smiling ðŸ˜Š\", (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Smile Detection', frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbdd491",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfer\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fer'"
     ]
    }
   ],
   "source": [
    "import fer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37978c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python being used is at:\n",
      "c:\\Users\\LENOVO\\.conda\\envs\\KNCVU\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python being used is at:\")\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659e3320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fer\n",
      "  Using cached fer-22.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from fer) (3.10.3)\n",
      "Collecting opencv-contrib-python (from fer)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting keras>=2.0.0 (from fer)\n",
      "  Using cached keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from fer) (2.2.2)\n",
      "Collecting requests (from fer)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting facenet-pytorch (from fer)\n",
      "  Using cached facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from fer) (4.67.1)\n",
      "Collecting moviepy (from fer)\n",
      "  Using cached moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: ffmpeg==1.4 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from fer) (1.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from fer) (10.2.0)\n",
      "Collecting absl-py (from keras>=2.0.0->fer)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from keras>=2.0.0->fer) (1.26.4)\n",
      "Collecting rich (from keras>=2.0.0->fer)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from keras>=2.0.0->fer) (0.1.0)\n",
      "Collecting h5py (from keras>=2.0.0->fer)\n",
      "  Using cached h5py-3.14.0-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: optree in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from keras>=2.0.0->fer) (0.16.0)\n",
      "Collecting ml-dtypes (from keras>=2.0.0->fer)\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from keras>=2.0.0->fer) (25.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->fer) (0.4.6)\n",
      "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch->fer)\n",
      "  Using cached torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch->fer)\n",
      "  Using cached torchvision-0.17.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->fer)\n",
      "  Using cached charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->fer)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from requests->fer) (2.5.0)\n",
      "Collecting certifi>=2017.4.17 (from requests->fer)\n",
      "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting filelock (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (4.14.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (1.14.0)\n",
      "Collecting networkx (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (3.1.4)\n",
      "Collecting fsspec (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from matplotlib->fer) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from matplotlib->fer) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from matplotlib->fer) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from matplotlib->fer) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from matplotlib->fer) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->fer) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->fer) (1.16.0)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from moviepy->fer) (5.2.1)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy->fer)\n",
      "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy->fer)\n",
      "  Using cached imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting proglog<=1.0.0 (from moviepy->fer)\n",
      "  Using cached proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from moviepy->fer) (1.1.1)\n",
      "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-contrib-python (from fer)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from pandas->fer) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from pandas->fer) (2024.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=2.0.0->fer)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from rich->keras>=2.0.0->fer) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->fer)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\.conda\\envs\\kncvu\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (1.3.0)\n",
      "Using cached fer-22.5.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "Using cached torchvision-0.17.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached h5py-3.14.0-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl (209 kB)\n",
      "Using cached moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
      "Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Using cached proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
      "Using cached imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: opencv-contrib-python, networkx, ml-dtypes, mdurl, imageio_ffmpeg, imageio, idna, h5py, fsspec, filelock, charset_normalizer, certifi, absl-py, torch, requests, proglog, markdown-it-py, torchvision, rich, moviepy, keras, facenet-pytorch, fer\n",
      "\n",
      "   ----------------------------------------  0/23 [opencv-contrib-python]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\Users\\\\LENOVO\\\\.conda\\\\envs\\\\KNCVU\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install fer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d69d3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda activate KNCVU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498e16e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3709277680.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip uninstall opencv-python opencv-contrib-python -y\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip uninstall opencv-python opencv-contrib-python -y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29bc4d07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize video capture and FER detector\u001b[39;00m\n\u001b[32m      2\u001b[39m cam = cv2.VideoCapture(\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m detector = \u001b[43mfer\u001b[49m(mtcnn=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cam.isOpened():\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mError: Camera not accessible\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'fer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize video capture and FER detector\n",
    "cam = cv2.VideoCapture(0)\n",
    "detector = fer(mtcnn=True)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    print(\"Error: Camera not accessible\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Detect emotions in the frame\n",
    "    result = detector.detect_emotions(frame)\n",
    "\n",
    "    for face in result:\n",
    "        (x, y, w, h) = face[\"box\"]\n",
    "        emotions = face[\"emotions\"]\n",
    "        top_emotion = max(emotions, key=emotions.get)\n",
    "\n",
    "        # Draw face box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "        \n",
    "        # Draw emotion label\n",
    "        label = f\"{top_emotion} ðŸ˜¢\" if top_emotion == \"sad\" else top_emotion\n",
    "        cv2.putText(frame, label, (x, y - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KNCVU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
